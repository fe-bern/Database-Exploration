version: '3'
Loader=yaml.Loader
services:

  data_collector:
    build: data_collector/
    volumes:
    - ./data_collector/:/code
    links:
    - mysql

  mysql:
    image: mysql/mysql-server
    restart: always
    environment:
      MYSQL_DATABASE: !secret MYSQL_DATABASE
      MYSQL_USER: !secret MYSQL_USER
      MYSQL_PASSWORD: !secret MYSQL_PASSWORD
    ports:
    - 3306:3306
    expose:
    - 3306

  airflow:
    image: puckel/docker-airflow
    volumes:
    - ./docker-airflow/dags/:/usr/local/airflow/dags/
    - ./docker-airflow/requirements.txt:/requirements.txt
    ports:
    - "8081:8080"
    environment:
    - LOAD_EX=y
    command: ["webserver", "scheduler"]

  postgres:
    image: postgres
    environment:
    - POSTGRES_PASSWORD: !secret POSTGRES_PASSWORD
    ports:
    - 5555:5432

  data_transformer:
    build: data_transformer/
    volumes:
    - ./data_transformer/:/code
    links:
    - mysql
    - postgres
    - data_collector

  mongodb:
    image: mongo
    ports:
    - 27017:27017
    links:
    - postgres

  redis:
    image: redis
    ports:
    - 6379:6379

  # data_analyzer:
  #   spark-master:
  #     image: bde2020/spark-master:3.0.0-hadoop3.2
  #     container_name: spark-master
  #     ports:
  #       - 8080:8080
  #       - 7077:7077
  #     environment:
  #       - INIT_DAEMON_STEP=setup_spark
  #       - constraint:node==<yourmasternode>
  #   spark-worker-1:
  #     image: bde2020/spark-worker:3.0.0-hadoop3.2
  #     container_name: spark-worker-1
  #     depends_on:
  #       - spark-master
  #     ports:
  #       - 8081:8081
  #     environment:
  #       - SPARK_MASTER=spark://spark-master:7077
  #       - constraint:node==<yourworkernode>
